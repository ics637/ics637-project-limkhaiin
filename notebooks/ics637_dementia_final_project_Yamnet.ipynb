{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urBpRWDHTHHU",
        "outputId": "862b4ead-ac41-4c6d-bb43-b8f451cdecf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.10/dist-packages (0.32.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io) (0.32.0)\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "!pip install tensorflow\n",
        "# tensorflow_io 0.28 is compatible with TensorFlow 2.11\n",
        "!pip install tensorflow_io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l3nqdWVF-kC"
      },
      "outputs": [],
      "source": [
        "#import pacakges\n",
        "import os\n",
        "\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_io as tfio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIOH_5A1YYnL"
      },
      "source": [
        "# **Load the Yamnet model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06CWkBV5v3gr"
      },
      "outputs": [],
      "source": [
        "# load yamnet model\n",
        "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
        "yamnet_model = hub.load(yamnet_model_handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yIXp9cvWYEB",
        "outputId": "4467642c-6a21-48bc-9235-7f1acb20e1c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speech\n",
            "Child speech, kid speaking\n",
            "Conversation\n",
            "Narration, monologue\n",
            "Babbling\n",
            "Speech synthesizer\n",
            "Shout\n",
            "Bellow\n",
            "Whoop\n",
            "Yell\n",
            "Children shouting\n",
            "Screaming\n",
            "Whispering\n",
            "Laughter\n",
            "Baby laughter\n",
            "Giggle\n",
            "Snicker\n",
            "Belly laugh\n",
            "Chuckle, chortle\n",
            "Crying, sobbing\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "# classes which the Yamnet model can classify into\n",
        "class_map_path = yamnet_model.class_map_path().numpy().decode('utf-8')\n",
        "class_names =list(pd.read_csv(class_map_path)['display_name'])\n",
        "\n",
        "for name in class_names[:20]:\n",
        "  print(name)\n",
        "print('...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZRGuv54Yfkh"
      },
      "source": [
        "# **Data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwc9Wrdg2EtY"
      },
      "outputs": [],
      "source": [
        "# Utility functions for loading audio files and making sure the sample rate is correct.\n",
        "@tf.function\n",
        "def load_wav_16k_mono(filename):\n",
        "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "    wav, sample_rate = tf.audio.decode_wav(\n",
        "          file_contents,\n",
        "          desired_channels=1)\n",
        "    wav = tf.squeeze(wav, axis=-1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6b4oyA1zkyq"
      },
      "outputs": [],
      "source": [
        "# a fold column for train-valid split. The training data will be split into an 8:2 ratio. \n",
        "# Only 250 wav files are utilized for training because the extract_embeddings function finds N frames for one file, which can cause the number of training data to blow.\n",
        "import random\n",
        "all_folds = [1] * 320 + [5] * 80\n",
        "random.shuffle(all_folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZdISjuXQags"
      },
      "outputs": [],
      "source": [
        "# load the path of control (non-patient) and dementia (patient) datasets\n",
        "import glob\n",
        "control_filenames=glob.glob(\"/content/drive/MyDrive/Colab Notebooks/dementia/English/Pitt/train/control/*.wav\")\n",
        "control_labels=(len(control_filenames[0:200]))*[0]\n",
        "demantia_filenames=glob.glob(\"/content/drive/MyDrive/Colab Notebooks/dementia/English/Pitt/train/dementia/*.wav\")\n",
        "dementia_labels=(len(demantia_filenames[0:200]))*[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7VBA85XSOfV"
      },
      "outputs": [],
      "source": [
        "# combine two datasets into one \n",
        "all_filenames=control_filenames[0:200]+demantia_filenames[200:400]\n",
        "all_labels=control_labels+dementia_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY2OBins5Fxj",
        "outputId": "965a4392-54ab-4dd4-e26c-7268bae6c42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              filename  label  fold\n",
            "0    /content/drive/MyDrive/Colab Notebooks/dementi...      0     5\n",
            "1    /content/drive/MyDrive/Colab Notebooks/dementi...      0     1\n",
            "2    /content/drive/MyDrive/Colab Notebooks/dementi...      0     1\n",
            "3    /content/drive/MyDrive/Colab Notebooks/dementi...      0     1\n",
            "4    /content/drive/MyDrive/Colab Notebooks/dementi...      0     1\n",
            "..                                                 ...    ...   ...\n",
            "395  /content/drive/MyDrive/Colab Notebooks/dementi...      1     1\n",
            "396  /content/drive/MyDrive/Colab Notebooks/dementi...      1     1\n",
            "397  /content/drive/MyDrive/Colab Notebooks/dementi...      1     1\n",
            "398  /content/drive/MyDrive/Colab Notebooks/dementi...      1     1\n",
            "399  /content/drive/MyDrive/Colab Notebooks/dementi...      1     1\n",
            "\n",
            "[400 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# put training data into a DataFrame to visualize the training data\n",
        "df = pd.DataFrame({'filename': all_filenames, 'label': all_labels, 'fold':all_folds})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-JRG0hCjbho"
      },
      "outputs": [],
      "source": [
        "# shuffle the Dataframe and the order of datasets during the training will be random\n",
        "df=df.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raUKWkfHQygU",
        "outputId": "f25b3207-1caa-4d91-979a-f48d716838a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load paths, labels and folds into a tf.Dataset objectt\n",
        "filenames = df['filename']\n",
        "labels = df['label']\n",
        "folds = df['fold']\n",
        "\n",
        "main_ds= tf.data.Dataset.from_tensor_slices((filenames, labels, folds))\n",
        "main_ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afmqGvi74d1y"
      },
      "outputs": [],
      "source": [
        "def load_wav_for_map(filename, label, fold):\n",
        "  return load_wav_16k_mono(filename), label, fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztrLDir2Ry1z",
        "outputId": "dcebe469-531b-4e99-aa8a-fc7ce00938c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load and resample the training data\n",
        "main_ds = main_ds.map(load_wav_for_map)\n",
        "main_ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dm-SQ2p-Upu"
      },
      "outputs": [],
      "source": [
        "# Yamnet is a feature extractor to extract features from the audio file.\n",
        "def extract_embedding(wav_data, label, fold):\n",
        "  ''' run YAMNet to extract embedding from the wav data '''\n",
        "  scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
        "  num_embeddings = tf.shape(embeddings[0:20])[0]\n",
        "  return (embeddings[0:20],\n",
        "            tf.repeat(label, num_embeddings),\n",
        "            tf.repeat(fold, num_embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6_Y5huuayTJ",
        "outputId": "94212f2f-8adb-4c5c-e1ae-e2ddaeca387d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(1024,), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract embeddings using Yamnet\n",
        "main_ds = main_ds.map(extract_embedding).unbatch()\n",
        "main_ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZYvlFiVsffC"
      },
      "outputs": [],
      "source": [
        "# split the data into train and validation set\n",
        "cached_ds = main_ds.cache()\n",
        "train_ds = cached_ds.filter(lambda embedding, label, fold: fold < 4)\n",
        "val_ds = cached_ds.filter(lambda embedding, label, fold: fold == 5)\n",
        "\n",
        "# remove the folds column now that it's not needed anymore\n",
        "remove_fold_column = lambda embedding, label, fold: (embedding, label)\n",
        "\n",
        "train_ds = train_ds.map(remove_fold_column)\n",
        "val_ds = val_ds.map(remove_fold_column)\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5PaMwvtcAIe"
      },
      "source": [
        "## Create the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYCE0Fr1GpN3",
        "outputId": "a6bcf9c7-ac54-4c4f-e89d-a06e599f7eb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 525,826\n",
            "Trainable params: 525,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build and compile the model\n",
        "my_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(1024), dtype=tf.float32,\n",
        "                          name='input_embedding'),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2)\n",
        "], name='my_model')\n",
        "\n",
        "my_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1qgH35HY0SE"
      },
      "outputs": [],
      "source": [
        "my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                 optimizer='adam',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=10,\n",
        "                                            restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3sj84eOZ3pk",
        "outputId": "f36ee657-4e3f-43b8-ce3c-acb58b516406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2713/2713 [==============================] - 26s 9ms/step - loss: 0.4763 - accuracy: 0.7834 - val_loss: 0.7284 - val_accuracy: 0.6859\n",
            "Epoch 2/50\n",
            "2713/2713 [==============================] - 28s 10ms/step - loss: 0.4543 - accuracy: 0.7913 - val_loss: 0.7712 - val_accuracy: 0.6922\n",
            "Epoch 3/50\n",
            "2713/2713 [==============================] - 26s 9ms/step - loss: 0.4441 - accuracy: 0.7975 - val_loss: 0.6959 - val_accuracy: 0.6929\n",
            "Epoch 4/50\n",
            "2713/2713 [==============================] - 25s 9ms/step - loss: 0.4352 - accuracy: 0.8040 - val_loss: 0.8326 - val_accuracy: 0.6679\n",
            "Epoch 5/50\n",
            "2713/2713 [==============================] - 37s 14ms/step - loss: 0.4279 - accuracy: 0.8077 - val_loss: 0.9748 - val_accuracy: 0.6367\n",
            "Epoch 6/50\n",
            "2713/2713 [==============================] - 24s 9ms/step - loss: 0.4204 - accuracy: 0.8103 - val_loss: 0.8169 - val_accuracy: 0.6638\n",
            "Epoch 7/50\n",
            "2713/2713 [==============================] - 24s 9ms/step - loss: 0.4086 - accuracy: 0.8167 - val_loss: 0.8170 - val_accuracy: 0.6659\n",
            "Epoch 8/50\n",
            "2713/2713 [==============================] - 25s 9ms/step - loss: 0.3999 - accuracy: 0.8220 - val_loss: 0.7857 - val_accuracy: 0.6677\n",
            "Epoch 9/50\n",
            "2713/2713 [==============================] - 25s 9ms/step - loss: 0.3903 - accuracy: 0.8258 - val_loss: 0.9259 - val_accuracy: 0.6537\n",
            "Epoch 10/50\n",
            "2713/2713 [==============================] - 25s 9ms/step - loss: 0.3802 - accuracy: 0.8336 - val_loss: 0.8118 - val_accuracy: 0.6712\n",
            "Epoch 11/50\n",
            "2713/2713 [==============================] - 25s 9ms/step - loss: 0.3726 - accuracy: 0.8362 - val_loss: 0.8977 - val_accuracy: 0.6590\n",
            "Epoch 12/50\n",
            "2713/2713 [==============================] - 24s 9ms/step - loss: 0.3675 - accuracy: 0.8397 - val_loss: 0.8731 - val_accuracy: 0.6636\n",
            "Epoch 13/50\n",
            "2713/2713 [==============================] - 24s 9ms/step - loss: 0.3567 - accuracy: 0.8453 - val_loss: 0.8961 - val_accuracy: 0.6523\n"
          ]
        }
      ],
      "source": [
        "history = my_model.fit(train_ds,\n",
        "                       epochs=50, batch_size=16, \n",
        "                       validation_data=val_ds,\n",
        "                       callbacks=callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lPYcKcoVB_C"
      },
      "source": [
        "# Test the model using a ADRess 2021 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqSXtZVl9zJa"
      },
      "outputs": [],
      "source": [
        "# Perform same data preprocessing as the training data\n",
        "import glob\n",
        "control_test_filenames=glob.glob('/content/drive/MyDrive/Colab Notebooks/dementia/English/ADReSS-2021/audio/control/*.wav')\n",
        "control_test_labels=(len(control_test_filenames))*[0]\n",
        "dementia_test_filenames=glob.glob('/content/drive/MyDrive/Colab Notebooks/dementia/English/ADReSS-2021/audio/dementia/*.wav')\n",
        "dementia_test_labels=(len(dementia_test_filenames))*[1]\n",
        "all_test_filenames=control_test_filenames+dementia_test_filenames\n",
        "all_test_labels=control_test_labels+dementia_test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UReh-WQRy0z"
      },
      "outputs": [],
      "source": [
        "all_test_folds = [6]*1444"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj0wchupSDls"
      },
      "outputs": [],
      "source": [
        "test_ds=tf.data.Dataset.from_tensor_slices((all_test_filenames, all_test_labels, all_test_folds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFx2cvPQSW2u",
        "outputId": "ea542e89-0bcd-4969-ec34-0c65611097b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int32, name=None))"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_ds = test_ds.map(load_wav_for_map)\n",
        "test_ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTMx4o4qSb9C",
        "outputId": "9be92e91-9c51-49bc-c9bd-d2390924cdeb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(1024,), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int32, name=None))"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_ds = test_ds.map(extract_embedding).unbatch()\n",
        "test_ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8D6KWo7SnNn"
      },
      "outputs": [],
      "source": [
        "remove_fold_column = lambda embedding, label, fold: (embedding, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgfs2nr_SrNm"
      },
      "outputs": [],
      "source": [
        "test_ds = test_ds.map(remove_fold_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHCyoJ-tSuBQ"
      },
      "outputs": [],
      "source": [
        "test_ds = test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7W7IXhdSy_T",
        "outputId": "1d969f64-6f0b-4765-9d77-28528c18d17e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 59s 542ms/step - loss: 1.1387 - Accuracy: 0.5000\n",
            "1.1386741399765015\n",
            "0.5\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test set\n",
        "loss, accuracy = my_model.evaluate(test_ds, verbose=1)\n",
        "print(loss)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMYeVanwcrRc"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "my_model.save('/content/drive/MyDrive/Colab Notebooks/dementia/tensorflow_model_0510.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0OmM6lvXWfS"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "my_model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/dementia/tensorflow_model.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
